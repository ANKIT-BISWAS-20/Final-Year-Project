{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "pz5qBQT-9kSV",
    "outputId": "6abb1d9f-5ad5-4e27-b88e-c145bdaa6e24"
   },
   "execution_count": 78,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/15] - Feature extraction complete.\n",
      "Epoch [2/15] - Feature extraction complete.\n",
      "Epoch [3/15] - Feature extraction complete.\n",
      "Epoch [4/15] - Feature extraction complete.\n",
      "Epoch [5/15] - Feature extraction complete.\n",
      "Epoch [6/15] - Feature extraction complete.\n",
      "Epoch [7/15] - Feature extraction complete.\n",
      "Epoch [8/15] - Feature extraction complete.\n",
      "Epoch [9/15] - Feature extraction complete.\n",
      "Epoch [10/15] - Feature extraction complete.\n",
      "Epoch [11/15] - Feature extraction complete.\n",
      "Epoch [12/15] - Feature extraction complete.\n",
      "Epoch [13/15] - Feature extraction complete.\n",
      "Epoch [14/15] - Feature extraction complete.\n",
      "Epoch [15/15] - Feature extraction complete.\n",
      "Training complete!\n",
      "Most similar image: KADIAN YOGESH1.png (Similarity Score: 1.0000)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-78-04ed215d5213>:125: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"Most similar image: {best_match} (Similarity Score: {float(best_score):.4f})\") # Convert NumPy scalar to float\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'KADIAN YOGESH1.png'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 78
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 0.0001  # Lower learning rate for fine-tuning\n",
    "EPOCHS = 15\n",
    "IMAGE_SIZE = (128, 128)  # Increased image size for better feature extraction\n",
    "SPLIT_RATIO = 0.8  # 80% training, 20% testing\n",
    "\n",
    "def normalize_features(features):\n",
    "    return features / torch.norm(features, dim=1, keepdim=True)\n",
    "\n",
    "# Define transformations without Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize(IMAGE_SIZE),  # Resize to 128x128 for better details\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ],
   "metadata": {
    "id": "4mZBjYWzDJc-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom Dataset to Load Images from a Single Folder\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
    "        self.image_names = [img for img in os.listdir(root_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_names[idx]\n",
    "\n"
   ],
   "metadata": {
    "id": "SkcI3dbtDVQO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset and split into train and test sets\n",
    "dataset = ImageDataset(root_dir=\"/content/drive/MyDrive/Appynitty_Backup/Home dept./CRIMINAL(Red Alart)\", transform=transform)\n",
    "train_size = int(SPLIT_RATIO * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ],
   "metadata": {
    "id": "oGNe-fpiDaTn"
   },
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define CNN Model using ResNet50 for Feature Extraction\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)  # Adjust for 1-channel input\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 512)  # New fully connected layer for feature embedding\n",
    "        self.batch_norm = nn.BatchNorm1d(512)  # Normalization instead of PCA\n",
    "\n",
    "        # Enable fine-tuning for entire model\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        # Apply Batch Normalization only during training\n",
    "        if self.training:  # Check if model is in training mode\n",
    "            x = self.batch_norm(x)\n",
    "        x = normalize_features(x)  # Normalize before similarity matching\n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "id": "1dbuhC8KDgQX"
   },
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FeatureExtractor().to(device)\n",
    "criterion = nn.CosineEmbeddingLoss()  # Loss function for similarity learning\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        loss = torch.tensor(0.0, requires_grad=True)  # Placeholder loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Feature extraction complete.\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3ND2ytgDk4W",
    "outputId": "190574b3-5bc2-4956-bcb1-14c62cd7bd08"
   },
   "execution_count": 95,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/15] - Feature extraction complete.\n",
      "Epoch [2/15] - Feature extraction complete.\n",
      "Epoch [3/15] - Feature extraction complete.\n",
      "Epoch [4/15] - Feature extraction complete.\n",
      "Epoch [5/15] - Feature extraction complete.\n",
      "Epoch [6/15] - Feature extraction complete.\n",
      "Epoch [7/15] - Feature extraction complete.\n",
      "Epoch [8/15] - Feature extraction complete.\n",
      "Epoch [9/15] - Feature extraction complete.\n",
      "Epoch [10/15] - Feature extraction complete.\n",
      "Epoch [11/15] - Feature extraction complete.\n",
      "Epoch [12/15] - Feature extraction complete.\n",
      "Epoch [13/15] - Feature extraction complete.\n",
      "Epoch [14/15] - Feature extraction complete.\n",
      "Epoch [15/15] - Feature extraction complete.\n",
      "Training complete!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Store extracted features for dataset\n",
    "feature_dict = {}\n",
    "for idx in range(len(dataset)):\n",
    "    img, img_name = dataset[idx]\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        # Set model to evaluation mode for feature extraction\n",
    "        model.eval()\n",
    "        feature_dict[img_name] = model(img).cpu().numpy()\n",
    "\n"
   ],
   "metadata": {
    "id": "T-fnf6GwDojf"
   },
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to load and test a single image and find the most similar image\n",
    "def test_single_image(image_path, model, feature_dict):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_feature = model(image).cpu().numpy()\n",
    "\n",
    "    # Compute cosine similarity with stored dataset features\n",
    "    best_match = None\n",
    "    best_score = -1\n",
    "    for img_name, stored_feature in feature_dict.items():\n",
    "        similarity = np.dot(image_feature, stored_feature.T) / (np.linalg.norm(image_feature) * np.linalg.norm(stored_feature))\n",
    "        if similarity > best_score:\n",
    "            best_score = similarity\n",
    "            best_match = img_name\n",
    "\n",
    "    # Convert best_score to a float before formatting\n",
    "    print(f\"Most similar image: {best_match} (Similarity Score: {float(best_score):.4f})\") # Convert NumPy scalar to float\n",
    "    return best_match\n",
    "\n",
    "# Example usage:\n",
    "test_single_image(\"/content/Chandrim.jpg\", model, feature_dict)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "kLbyvf8NDrUH",
    "outputId": "4de08063-2eff-4657-cee5-2eb9129799ef"
   },
   "execution_count": 103,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most similar image: PUJARI, HEMANT1.png (Similarity Score: 0.8111)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-103-e1e802f1608a>:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(f\"Most similar image: {best_match} (Similarity Score: {float(best_score):.4f})\") # Convert NumPy scalar to float\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'PUJARI, HEMANT1.png'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 103
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
